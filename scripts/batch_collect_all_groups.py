#!/usr/bin/env python3
"""ì „ì²´ ê·¸ë£¹ ì¬ë¬´ì œí‘œ ë°°ì¹˜ ìˆ˜ì§‘ ìŠ¤í¬ë¦½íŠ¸.

ëª¨ë“  ë°°ì¹˜ ê·¸ë£¹ì— ëŒ€í•´ ìˆœì°¨ì ìœ¼ë¡œ ì¬ë¬´ì œí‘œë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤.
ê° ê·¸ë£¹ì€ checkpoint ì§€ì›ìœ¼ë¡œ ì¤‘ë‹¨ ì‹œ ì¬ê°œ ê°€ëŠ¥í•©ë‹ˆë‹¤.

Usage:
    # ì „ì²´ ê·¸ë£¹ ìˆ˜ì§‘ (ê¸°ë³¸: 2024, 2023, 2022)
    python scripts/batch_collect_all_groups.py

    # íŠ¹ì • ì—°ë„ë§Œ ìˆ˜ì§‘
    python scripts/batch_collect_all_groups.py --years 2024 2023

    # íŠ¹ì • ê·¸ë£¹ë¶€í„° ì‹œì‘
    python scripts/batch_collect_all_groups.py --start-group 3

    # ê° ê·¸ë£¹ ì™„ë£Œ í›„ ëŒ€ê¸° ì‹œê°„ ì„¤ì • (ì´ˆ)
    python scripts/batch_collect_all_groups.py --delay 10
"""

import sys
from pathlib import Path
import argparse
import json
import subprocess
from datetime import datetime
import time

# Add project root to path
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from loguru import logger

# Configure logger
logger.add(
    "logs/batch_collect_all_groups_{time}.log",
    rotation="1 day",
    retention="30 days",
    level="INFO"
)


def load_group_summary():
    """ë°°ì¹˜ ê·¸ë£¹ ìš”ì•½ ì •ë³´ ë¡œë“œ."""
    summary_path = project_root / "data" / "batch_groups" / "batch_groups_summary.json"

    if not summary_path.exists():
        raise FileNotFoundError(f"Group summary not found: {summary_path}")

    with open(summary_path, 'r') as f:
        return json.load(f)


def collect_group(group_id: int, years: list, resume: bool = False):
    """íŠ¹ì • ê·¸ë£¹ ì¬ë¬´ì œí‘œ ìˆ˜ì§‘.

    Args:
        group_id: ê·¸ë£¹ ID
        years: ìˆ˜ì§‘í•  ì—°ë„ ë¦¬ìŠ¤íŠ¸
        resume: checkpointì—ì„œ ì¬ê°œ ì—¬ë¶€

    Returns:
        bool: ì„±ê³µ ì—¬ë¶€
    """
    logger.info(f"{'='*80}")
    logger.info(f"Starting collection for Group {group_id}")
    logger.info(f"{'='*80}")

    cmd = [
        "python",
        str(project_root / "scripts" / "batch_collect_financials.py"),
        "--group", str(group_id),
        "--years"
    ] + [str(y) for y in years]

    if resume:
        cmd.append("--resume")

    try:
        result = subprocess.run(
            cmd,
            cwd=str(project_root),
            capture_output=False,  # Show output in real-time
            text=True,
            check=True
        )

        logger.success(f"âœ“ Group {group_id} completed successfully")
        return True

    except subprocess.CalledProcessError as e:
        logger.error(f"âœ— Group {group_id} failed with exit code {e.returncode}")
        return False
    except Exception as e:
        logger.exception(f"âœ— Group {group_id} failed with error: {e}")
        return False


def main():
    parser = argparse.ArgumentParser(description="Batch collect all groups")
    parser.add_argument(
        '--years',
        type=int,
        nargs='+',
        default=[2024, 2023, 2022],
        help='Years to collect (default: 2024 2023 2022)'
    )
    parser.add_argument(
        '--start-group',
        type=int,
        default=1,
        help='Start from this group (default: 1)'
    )
    parser.add_argument(
        '--end-group',
        type=int,
        default=None,
        help='End at this group (default: last group)'
    )
    parser.add_argument(
        '--delay',
        type=int,
        default=5,
        help='Delay between groups in seconds (default: 5)'
    )
    parser.add_argument(
        '--resume',
        action='store_true',
        help='Resume from checkpoints for each group'
    )

    args = parser.parse_args()

    # Load group summary
    try:
        summary = load_group_summary()
        num_groups = summary['num_groups']
        total_stocks = summary['total_stocks']
    except Exception as e:
        logger.error(f"Failed to load group summary: {e}")
        return 1

    # Determine groups to process
    start_group = args.start_group
    end_group = args.end_group if args.end_group else num_groups

    if start_group < 1 or start_group > num_groups:
        logger.error(f"Invalid start group: {start_group} (must be 1-{num_groups})")
        return 1

    if end_group < start_group or end_group > num_groups:
        logger.error(f"Invalid end group: {end_group} (must be {start_group}-{num_groups})")
        return 1

    groups_to_process = list(range(start_group, end_group + 1))

    # Print summary
    print("=" * 80)
    print("ğŸ“Š ì „ì²´ ë°°ì¹˜ ìˆ˜ì§‘ ì‹œì‘")
    print("=" * 80)
    print(f"ì´ ì¢…ëª© ìˆ˜:       {total_stocks:,}ê°œ")
    print(f"ì´ ê·¸ë£¹ ìˆ˜:       {num_groups}ê°œ")
    print(f"ì²˜ë¦¬í•  ê·¸ë£¹:      {start_group} ~ {end_group} ({len(groups_to_process)}ê°œ)")
    print(f"ìˆ˜ì§‘ ì—°ë„:        {', '.join(map(str, args.years))}")
    print(f"ê·¸ë£¹ê°„ ëŒ€ê¸°:      {args.delay}ì´ˆ")
    print(f"Checkpoint ì¬ê°œ:  {'ì˜ˆ' if args.resume else 'ì•„ë‹ˆì˜¤'}")
    print("=" * 80)
    print()

    # Confirm
    response = input("ê³„ì† ì§„í–‰í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/N): ").strip().lower()
    if response != 'y':
        print("ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤.")
        return 0

    print()

    # Process groups
    start_time = datetime.now()
    success_count = 0
    failed_groups = []

    for i, group_id in enumerate(groups_to_process, 1):
        logger.info(f"\n[{i}/{len(groups_to_process)}] Processing Group {group_id}...")

        success = collect_group(group_id, args.years, args.resume)

        if success:
            success_count += 1
        else:
            failed_groups.append(group_id)
            logger.warning(f"Group {group_id} failed - continuing to next group...")

        # Delay between groups (except after last group)
        if i < len(groups_to_process) and args.delay > 0:
            logger.info(f"Waiting {args.delay} seconds before next group...")
            time.sleep(args.delay)

    # Summary
    end_time = datetime.now()
    duration = end_time - start_time

    print()
    print("=" * 80)
    print("ğŸ“Š ì „ì²´ ë°°ì¹˜ ìˆ˜ì§‘ ì™„ë£Œ")
    print("=" * 80)
    print(f"ì²˜ë¦¬í•œ ê·¸ë£¹:      {len(groups_to_process)}ê°œ")
    print(f"ì„±ê³µ:            {success_count}ê°œ")
    print(f"ì‹¤íŒ¨:            {len(failed_groups)}ê°œ")
    if failed_groups:
        print(f"ì‹¤íŒ¨í•œ ê·¸ë£¹:      {', '.join(map(str, failed_groups))}")
    print(f"ì†Œìš” ì‹œê°„:        {duration}")
    print("=" * 80)

    if failed_groups:
        print()
        print("âš ï¸  ì¼ë¶€ ê·¸ë£¹ ìˆ˜ì§‘ ì‹¤íŒ¨. ë‹¤ìŒ ëª…ë ¹ìœ¼ë¡œ ì¬ì‹œë„:")
        for group_id in failed_groups:
            print(f"  python scripts/batch_collect_financials.py --group {group_id} --resume")

    logger.info(f"Total duration: {duration}")
    logger.info(f"Success: {success_count}/{len(groups_to_process)}")

    return 0 if not failed_groups else 1


if __name__ == "__main__":
    sys.exit(main())
